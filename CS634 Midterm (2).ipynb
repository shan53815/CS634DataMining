{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficient_apriori\n",
    "#!pip install mlxtend --user\n",
    "\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from efficient_apriori import apriori\n",
    "\n",
    "Amazon_url = 'https://github.com/shan53815/CS634DataMining/blob/main/Amazon.csv?raw=true'\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Perform Apriori algorithm\n",
    "itemsets, rules = apriori(data, min_support = 0.5, min_confidence=0.7)\n",
    "\n",
    "# Print frequent itemsets and association rules\n",
    "print(\"Frequent Itemsets:\")\n",
    "for itemset in itemsets:\n",
    "    print(itemset)\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "for rule in rules:\n",
    "    print(rule)\n",
    "\n",
    "# Convert data to transaction format\n",
    "transactions = []\n",
    "for index, row in data.iterrows():\n",
    "    transactions.append(row['Transaction'].split(', '))\n",
    "\n",
    "# Perform one-hot encoding to convert the dataset into a binary format\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "encoded_data = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Perform FP-Growth to find frequent itemsets\n",
    "frequent_itemsets = fpgrowth(encoded_data, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Print frequent itemsets\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Print association rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficient_apriori\n",
    "#!pip install mlxtend --user\n",
    "\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from efficient_apriori import apriori\n",
    "\n",
    "url = \"https://github.com/shan53815/CS634DataMining/blob/main/Best-Buy.csv?raw=true\"\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Perform Apriori algorithm\n",
    "itemsets, rules = apriori(data, min_support = 0.5, min_confidence=0.7)\n",
    "\n",
    "# Print frequent itemsets and association rules\n",
    "print(\"Frequent Itemsets:\")\n",
    "for itemset in itemsets:\n",
    "    print(itemset)\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "for rule in rules:\n",
    "    print(rule)\n",
    "\n",
    "# Convert data to transaction format\n",
    "transactions = []\n",
    "for index, row in data.iterrows():\n",
    "    transactions.append(row['Transaction'].split(', '))\n",
    "\n",
    "# Perform one-hot encoding to convert the dataset into a binary format\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "encoded_data = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Perform FP-Growth to find frequent itemsets\n",
    "frequent_itemsets = fpgrowth(encoded_data, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Print frequent itemsets\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Print association rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficient_apriori\n",
    "#!pip install mlxtend --user\n",
    "\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from efficient_apriori import apriori\n",
    "\n",
    "url = 'https://github.com/shan53815/CS634DataMining/blob/main/Generic.csv?raw=true'\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Perform Apriori algorithm\n",
    "itemsets, rules = apriori(data, min_support = 0.5, min_confidence=0.7)\n",
    "\n",
    "# Print frequent itemsets and association rules\n",
    "print(\"Frequent Itemsets:\")\n",
    "for itemset in itemsets:\n",
    "    print(itemset)\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "for rule in rules:\n",
    "    print(rule)\n",
    "\n",
    "# Convert data to transaction format\n",
    "transactions = []\n",
    "for index, row in data.iterrows():\n",
    "    transactions.append(row['Transaction'].split(', '))\n",
    "\n",
    "# Perform one-hot encoding to convert the dataset into a binary format\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "encoded_data = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Perform FP-Growth to find frequent itemsets\n",
    "frequent_itemsets = fpgrowth(encoded_data, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Print frequent itemsets\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Print association rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficient_apriori\n",
    "#!pip install mlxtend --user\n",
    "\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from efficient_apriori import apriori\n",
    "\n",
    "url = 'https://github.com/shan53815/CS634DataMining/blob/main/K-Mart.csv?raw=true'\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Perform Apriori algorithm\n",
    "itemsets, rules = apriori(data, min_support = 0.5, min_confidence=0.7)\n",
    "\n",
    "# Print frequent itemsets and association rules\n",
    "print(\"Frequent Itemsets:\")\n",
    "for itemset in itemsets:\n",
    "    print(itemset)\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "for rule in rules:\n",
    "    print(rule)\n",
    "\n",
    "# Convert data to transaction format\n",
    "transactions = []\n",
    "for index, row in data.iterrows():\n",
    "    transactions.append(row['Transaction'].split(', '))\n",
    "\n",
    "# Perform one-hot encoding to convert the dataset into a binary format\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "encoded_data = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Perform FP-Growth to find frequent itemsets\n",
    "frequent_itemsets = fpgrowth(encoded_data, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Print frequent itemsets\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Print association rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficient_apriori\n",
    "#!pip install mlxtend --user\n",
    "\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from efficient_apriori import apriori\n",
    "\n",
    "url = 'https://github.com/shan53815/CS634DataMining/blob/main/Nike.csv?raw=true'\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Perform Apriori algorithm\n",
    "itemsets, rules = apriori(data, min_support = 0.5, min_confidence=0.7)\n",
    "\n",
    "# Print frequent itemsets and association rules\n",
    "print(\"Frequent Itemsets:\")\n",
    "for itemset in itemsets:\n",
    "    print(itemset)\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "for rule in rules:\n",
    "    print(rule)\n",
    "\n",
    "# Convert data to transaction format\n",
    "transactions = []\n",
    "for index, row in data.iterrows():\n",
    "    transactions.append(row['Transaction'].split(', '))\n",
    "\n",
    "# Perform one-hot encoding to convert the dataset into a binary format\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "encoded_data = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Perform FP-Growth to find frequent itemsets\n",
    "frequent_itemsets = fpgrowth(encoded_data, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Print frequent itemsets\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Print association rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all three algorithms, generate and print out all the association rules \n",
    "#and the input transactions for each of the 5 transactional databases you created/used\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from efficient_apriori import apriori\n",
    "#from itertools import chain, combinations\n",
    "import pyfpgrowth\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    def powerset(iterable):\n",
    "        \"\"\"Return all possible subsets of items in iterable.\"\"\"\n",
    "        s = list(iterable)\n",
    "        return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "\n",
    "    def brute_force(data, min_support, min_confidence):\n",
    "        \"\"\"Generate frequent itemsets and association rules using a brute-force method.\"\"\"\n",
    "        # Calculate the support for each itemset\n",
    "        item_counts = {}\n",
    "        for transaction in data:\n",
    "            for item in transaction:\n",
    "                if item in item_counts:\n",
    "                    item_counts[item] += 1\n",
    "                else:\n",
    "                    item_counts[item] = 1\n",
    "\n",
    "        # Find frequent itemsets\n",
    "        num_transactions = len(data)\n",
    "        frequent_itemsets = []\n",
    "        for itemset in powerset(item_counts.keys()):\n",
    "            if len(itemset) > 0:\n",
    "                support = sum(1 for transaction in data if all(item in transaction for item in itemset)) / num_transactions\n",
    "                if support >= min_support:\n",
    "                    frequent_itemsets.append((itemset, support))\n",
    "\n",
    "        # Generate association rules\n",
    "        association_rules = []\n",
    "        for itemset, support in frequent_itemsets:\n",
    "            if len(itemset) > 1:\n",
    "                for subset in powerset(itemset):\n",
    "                    if len(subset) > 0 and len(subset) < len(itemset):\n",
    "                        confidence = support / sum(1 for transaction in data if all(item in transaction for item in subset))\n",
    "                        if confidence >= min_confidence:\n",
    "                            association_rules.append((subset, itemset.difference(subset), confidence))\n",
    "\n",
    "        return frequent_itemsets, association_rules\n",
    "\n",
    "    # Prompt user for input \n",
    "    dataset_path = input(\"https://github.com/shan53815/CS634DataMining/blob/main/Nike.csv?raw=true \")\n",
    "    min_support = float(input(\"0.1 \"))\n",
    "    min_confidence = float(input(\"0.7\"))\n",
    "\n",
    "    # Read dataset\n",
    "    data = pd.read_csv(dataset_path)\n",
    "\n",
    "    \n",
    "    # Perform brute-force algorithm\n",
    "    print(\"\\nBrute-force Algorithm:\")\n",
    "    frequent_itemsets, association_rules = brute_force(data, min_support, min_confidence)\n",
    "    print(\"Frequent Itemsets:\")\n",
    "    print(frequent_itemsets)\n",
    "    print(\"Association Rules:\")\n",
    "    print(association_rules)\n",
    "\n",
    "    # Perform Apriori algorithm\n",
    "    print(\"\\nApriori Algorithm:\")\n",
    "    frequent_itemsets, association_rules = apriori(data, min_support, min_confidence)\n",
    "    print(\"Frequent Itemsets:\")\n",
    "    print(frequent_itemsets)\n",
    "    print(\"Association Rules:\")\n",
    "    print(association_rules)\n",
    "\n",
    "    # Perform FP-Growth algorithm\n",
    "    print(\"\\nFP-Growth Algorithm:\")\n",
    "    frequent_itemsets, association_rules = fpgrowth(data, min_support, min_confidence)\n",
    "    print(\"Frequent Itemsets:\")\n",
    "    print(frequent_itemsets)\n",
    "    print(\"Association Rules:\")\n",
    "    print(association_rules)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyfpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
